{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff290c8",
   "metadata": {},
   "source": [
    "# Deep learning with Keras: part 2\n",
    "\n",
    "## Goal: Learn to train neural networks & experiment with example code\n",
    "\n",
    "## C) Sinogram inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0133e2",
   "metadata": {},
   "source": [
    "#### First import all the necessary packages. If you get an error here, make sure have actually installed the package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaf1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from tensorflow.keras import Model, layers, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Add, BatchNormalization, Convolution2D, UpSampling2D, Dense, MaxPooling2D, concatenate\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import skimage\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed6f11",
   "metadata": {},
   "source": [
    "#### Load the training data from directory (mat-files)\n",
    "\n",
    "https://www.dropbox.com/scl/fo/rk6l1fi2pjfsupplyc4ix/h?rlkey=59c0m80y6894f5tmn94tgtb4n&dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired dimensions for data\n",
    "N  = 128  # sinogram column\n",
    "M  = 16  # input rows\n",
    "M2 = 256 # outputrows\n",
    "X  = 1   # color channels\n",
    "\n",
    "# Import training input\n",
    "train_input = []\n",
    "files       = sorted(glob.glob(\"sinogram_train/*.mat\"))\n",
    "\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    mat    = scipy.io.loadmat(myFile)\n",
    "    matrix = mat['Rmu_big']\n",
    "    \n",
    "    # resize matrix\n",
    "    matrix_resized = cv2.resize(matrix, dsize=(M,N), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # pick every 8th row of matrix\n",
    "    #matrix_resized = matrix[::16]\n",
    "    \n",
    "    train_input.append(matrix_resized)  \n",
    "train_input = np.array(train_input)\n",
    "\n",
    "# Import training output (ground truth)\n",
    "train_gt = []\n",
    "files    = sorted(glob.glob(\"sinogram_train/*.mat\"))\n",
    "\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    mat    = scipy.io.loadmat(myFile)\n",
    "    matrix = mat['Rmu_big']\n",
    "    \n",
    "    # resize matrix\n",
    "    matrix_resized = cv2.resize(matrix, dsize=(M2,N), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    train_gt.append(matrix_resized)  \n",
    "train_gt = np.array(train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training set size\n",
    "\n",
    "print(train_input.shape) \n",
    "print(train_gt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11c45c",
   "metadata": {},
   "source": [
    "#### Pre-process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c750b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "print('Input value range:')\n",
    "min_input = np.amin(train_input)\n",
    "max_input = np.amax(train_input)\n",
    "print(min_input)\n",
    "print(max_input)\n",
    "train_input = (train_input - min_input) / (max_input - min_input)\n",
    "\n",
    "print('Output value range:')\n",
    "min_output = np.amin(train_gt)\n",
    "max_output = np.amax(train_gt)\n",
    "print(min_output)\n",
    "print(max_output)\n",
    "train_gt = (train_gt - min_output) / (max_output - min_output)\n",
    "\n",
    "print('Normalized input value range:')\n",
    "print(np.amin(train_gt))\n",
    "print(np.amax(train_gt))\n",
    "\n",
    "print('Normalized output value range:')\n",
    "print(np.amin(train_input))\n",
    "print(np.amax(train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: take a look at training data\n",
    "\n",
    "iii = randrange(50)\n",
    "print(iii)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (2,3)\n",
    "print('Example of input')\n",
    "im = train_input[iii,:,:]\n",
    "print(np.amin(im))\n",
    "print(np.amax(im))\n",
    "plt.imshow(train_input[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6,3)\n",
    "print('Example of output')\n",
    "im3 = train_gt[iii,:,:]\n",
    "print(np.amin(im3))\n",
    "print(np.amax(im3))\n",
    "plt.imshow(train_gt[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cbd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation set for training\n",
    "\n",
    "valid_size = 1000  \n",
    "train_gt, valid_gt       = train_test_split(train_gt, test_size=valid_size, shuffle=False)  \n",
    "train_input, valid_input = train_test_split(train_input, test_size=valid_size, shuffle=False)  \n",
    "\n",
    "print(np.amin(train_gt))\n",
    "print(np.amax(train_gt))\n",
    "\n",
    "print(np.amin(train_input))\n",
    "print(np.amax(train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14715b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: take a look at validation data\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "\n",
    "iii = randrange(valid_size)\n",
    "print(iii)\n",
    "\n",
    "print('Example of input')\n",
    "im = valid_input[iii,:,:]\n",
    "print(np.amin(im))\n",
    "print(np.amax(im))\n",
    "plt.imshow(valid_input[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Example of output')\n",
    "im3 = valid_gt[iii,:,:]\n",
    "print(np.amin(im3))\n",
    "print(np.amax(im3))\n",
    "plt.imshow(valid_gt[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reshape the image data to the format the neural network expects for training\n",
    "\n",
    "train_gt    = train_gt.reshape(-1,N,M2,X)\n",
    "train_input = train_input.reshape(-1,N,M,X)\n",
    "\n",
    "valid_gt    = valid_gt.reshape(-1,N,M2,X)\n",
    "valid_input = valid_input.reshape(-1,N,M,X)\n",
    "\n",
    "print(train_gt.shape)\n",
    "print(train_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e62e6",
   "metadata": {},
   "source": [
    "#### Neural network architecture: fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_network():  \n",
    "    inputs = Input(shape=(N,M,X))\n",
    "    \n",
    "    x = Dense(10, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=(1,2))(x)\n",
    "    \n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=(1,2))(x)\n",
    "    \n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=(1,2))(x)\n",
    "    \n",
    "    x = Dense(40, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=(1,2))(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    funcmodel = Model(inputs, x)\n",
    "    \n",
    "    funcmodel.compile(optimizer='adadelta', loss='MSE')\n",
    "    \n",
    "    return funcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b1974",
   "metadata": {},
   "source": [
    "#### Neural network architecture: convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CNN():\n",
    "    inputs = Input(shape=(N,M,X))\n",
    "    \n",
    "    u1 = Convolution2D(128, 3, activation='relu', padding='same')(inputs)\n",
    "    u1 = BatchNormalization()(u1)\n",
    "    u2 = UpSampling2D(size=(1,4))(u1)\n",
    "    \n",
    "    u2 = Convolution2D(64, 3, activation='relu', padding='same')(u2)\n",
    "    u2 = BatchNormalization()(u2)\n",
    "    u2 = UpSampling2D(size=(1,4))(u2)\n",
    "    \n",
    "    output = Convolution2D(X, 1, activation='sigmoid', padding='same')(u2)\n",
    "    \n",
    "    neural_network = Model(inputs, output)\n",
    "    neural_network.compile(optimizer='adam', loss='MSE')\n",
    "    \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5700a",
   "metadata": {},
   "source": [
    "#### Neural network architecture: Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_convolutional_autoencoder():\n",
    "    # encoding\n",
    "    inputs = Input(shape=(N,M,X))\n",
    "    \n",
    "    d1 = Convolution2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    d1 = BatchNormalization()(d1)\n",
    "    d2 = MaxPooling2D(padding='same')(d1)\n",
    "    \n",
    "    d3 = Convolution2D(128, 3, activation='relu', padding='same')(d2)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    encoded = MaxPooling2D(padding='same')(d3)    \n",
    "    \n",
    "    # decoding\n",
    "    u1 = Convolution2D(128, 3, activation='relu', padding='same')(encoded)\n",
    "    u1 = BatchNormalization()(u1)\n",
    "    u2 = UpSampling2D()(u1)\n",
    "    u2 = concatenate([u2, d3])\n",
    "    \n",
    "    u3 = Convolution2D(64, 3, activation='relu', padding='same')(u2)\n",
    "    u3 = BatchNormalization()(u3)\n",
    "    u4 = UpSampling2D()(u3)\n",
    "    u4 = concatenate([u4, d1])\n",
    "    \n",
    "    u5 = Convolution2D(32, 3, activation='relu', padding='same')(u4)\n",
    "    u5 = BatchNormalization()(u5)\n",
    "    u6 = UpSampling2D(size=(1,4))(u5)\n",
    "    \n",
    "    u7 = Convolution2D(16, 3, activation='relu', padding='same')(u6)\n",
    "    u7 = BatchNormalization()(u7)\n",
    "    u8 = UpSampling2D(size=(1,4))(u7)\n",
    "    \n",
    "    decoded = Convolution2D(X, 1, activation='sigmoid', padding='same')(u8)\n",
    "    \n",
    "    # autoencoder\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='MSE')\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "#neural_network = make_basic_network()\n",
    "#neural_network = make_CNN()\n",
    "neural_network = make_convolutional_autoencoder()\n",
    "\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00725d3",
   "metadata": {},
   "source": [
    "#### Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5496579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=6) #early stopping\n",
    "\n",
    "# train\n",
    "history = neural_network.fit(train_input, train_gt, epochs=3, batch_size=5, \n",
    "                             validation_data=(valid_input, valid_gt), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "neural_network.save('models/sinogram_inpainting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "loss_values = history.history['loss']\n",
    "epochs      = range(1,len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs,loss_values)\n",
    "plt.plot(epochs,history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.xlim([1, 10])\n",
    "plt.savefig('figures/loss_ellipse_superresolution_test1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bc4df",
   "metadata": {},
   "source": [
    "#### Test results with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "autoencoder = models.load_model('models/sinogram_inpainting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import testing input\n",
    "test_input = []\n",
    "files       = sorted(glob.glob(\"sinogram_train/*11.mat\"))\n",
    "\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    mat    = scipy.io.loadmat(myFile)\n",
    "    matrix = mat['Rmu_big']\n",
    "    \n",
    "    # resize matrix\n",
    "    matrix_resized = cv2.resize(matrix, dsize=(M,N), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # pick every 8th row of matrix\n",
    "    #matrix_resized = matrix[::16]\n",
    "    \n",
    "    test_input.append(matrix_resized)  \n",
    "test_input = np.array(test_input)\n",
    "\n",
    "# Import training output (ground truth)\n",
    "test_gt = []\n",
    "files    = sorted(glob.glob(\"sinogram_train/*11.mat\"))\n",
    "\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    mat    = scipy.io.loadmat(myFile)\n",
    "    matrix = mat['Rmu_big']\n",
    "    \n",
    "    # resize matrix\n",
    "    matrix_resized = cv2.resize(matrix, dsize=(M2,N), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    test_gt.append(matrix_resized)  \n",
    "test_gt = np.array(test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde59e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "print('Input value range:')\n",
    "min_input = np.amin(test_input)\n",
    "max_input = np.amax(test_input)\n",
    "print(min_input)\n",
    "print(max_input)\n",
    "test_input = (test_input - min_input) / (max_input - min_input)\n",
    "\n",
    "print('Output value range:')\n",
    "min_output = np.amin(test_gt)\n",
    "max_output = np.amax(test_gt)\n",
    "print(min_output)\n",
    "print(max_output)\n",
    "test_gt = (test_gt - min_output) / (max_output - min_output)\n",
    "\n",
    "print('Normalized input value range:')\n",
    "print(np.amin(test_gt))\n",
    "print(np.amax(test_gt))\n",
    "\n",
    "print('Normalized output value range:')\n",
    "print(np.amin(test_input))\n",
    "print(np.amax(test_input))\n",
    "\n",
    "print(test_gt.shape)\n",
    "print(test_input.shape)\n",
    "\n",
    "test_gt     = test_gt.reshape(-1,N,M2,X)\n",
    "test_input  = test_input.reshape(-1,N,M,X)\n",
    "\n",
    "print(test_gt.shape)\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict results on test set\n",
    "\n",
    "test_gt_decoded = neural_network.predict(test_input)\n",
    "print(test_gt_decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe29b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pass the testing inputs to the neural network to see the restored data\n",
    "\n",
    "iii = 0\n",
    "print(iii)\n",
    "\n",
    "print('Network input')\n",
    "im3 = test_input[iii,:,:]\n",
    "print(np.amin(im3))\n",
    "print(np.amax(im3))\n",
    "plt.imshow(test_input[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Network output')\n",
    "im3 = test_gt_decoded[iii,:,:]\n",
    "print(np.amin(im3))\n",
    "print(np.amax(im3))\n",
    "plt.imshow(test_gt_decoded[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Ground truth')\n",
    "im3 = test_gt[iii,:,:]\n",
    "print(np.amin(im3))\n",
    "print(np.amax(im3))\n",
    "plt.imshow(test_gt[iii,:,:], cmap=\"gray\",vmin=0, vmax=1,aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save whole test set as mat.-files\n",
    "\n",
    "for iii in range(len(test_gt_decoded)):\n",
    "    mydata   = test_gt_decoded[iii,:,:,:]\n",
    "    filename = \"results/sinogram_inpainting_%04.f.mat\" % iii\n",
    "    savemat(filename, {'mydata': mydata})\n",
    "    print(iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d32e7a",
   "metadata": {},
   "source": [
    "## To do: Experiment!\n",
    "#### Try out different hyperparameters for the neural networks. What yields the best results? Things to experiment with:\n",
    "\n",
    "- neural network type (compare number of learned parameters!)\n",
    "- number of neurons in each layer (make sure dimensions match the data!)\n",
    "- how many epochs necessary to reach convergence?\n",
    "- loss functions (mean squared error, custom loss functions?) \n",
    "- activation functions (relu, sigmoid, tanh...)\n",
    "- to use batch normalization or not?\n",
    "- optimizer (adam, adadelta, rmsprop...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d33b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
